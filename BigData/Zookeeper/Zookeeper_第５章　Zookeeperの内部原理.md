# 分散型協調サービスフレームワーク -- Zookeeper-5

## 第５章　Zookeeperの内部原理

### 第１節　Leaderの選挙機構

#### 選挙機構

- 半数以上の機器が稼働していれば、クラスタは利用可能です。従って、ZooKeeperは奇数台のサーバーで設定するのが適している。
- ZooKeeperの配置ファイルにはMasterやSlaveを指定する項目はないが、実際にはLeaderとFollowerという役割がある。ZooKeeperは内部の選挙機構によってLeader節点が選ばれ、他の節点はFollowerとなる。

#### 選挙過程

　　選挙過程が大体２種の場合が分けられる。

**初めて起動**

　　仮に、IDが1から5までの5台のサーバーで構成されたZooKeeperクラスターがあり、これらのサーバーは全て最新の起動であり、過去のデータは持ってないと仮定する。![image-20231023163347227](D:\OneDrive\图片\Typora\image-20231023163347227.png)

1. Server1が起動し、この時点ではServerのID最大の自分に投票してあげる。従って、Server1から発信されるメッセージには応答のサーバーがない。そのため、Server1の選挙の状態は常にLOOKING（リーダーの選出を待機中）の状態です。
2. Server2が起動し、同じに自分に投票してあげる。後で、最初に起動したServer1と投票結果を通信し、両者がお互いに選挙結果を交換することが行う。最初起動する場合はどちらも過去のデータがないので、ServerのID（myid）が大きいServer2が２票で勝利する。ただし、半数以上のサーバーが同意しなかったため（この例では半数以上が3台）、Server1と2は引き続きLOOKINGの状態を維持する。
3. Server3が起動する。前述の理論に基づいて半分以上台数の規則が満たし、Server3はServer1、2、3の中で最大のIDを持つため、3票を取得したServer3が順調にLeaderとなる。
4. Server4が起動します。前述の分析に基づいて、理論的にはServer4が最大のIDを持つはずですが、既にServer3を半数以上の投票で選出していたため、Server4はFollowerとして運行することになる。
5. Server5が起動する。Server4と同様にFollower役を担当する。

**初めて起動ではない**

　　半数以上のサーバーが稼働している状態を前提として、最大のトランザクションID（cZxid）を持つサーバーをLeaderに選挙してある。各サーバーの保存したcZxidが同じなら、myidが大きいのサーバーがLeaderを選出される。もしLeaderサーバーが故障などの原因で運行しなくなった場合、さっき言った規則に沿って改めて選挙を行う。Follower故障に対して残るサーバーが稼働し続き、特別な変更がない。故障サーバーが正常に復旧し、Leaderから最新のバックアップを取得して他のサーバーと一致するになる。

#### 選挙原理

　　実際の選挙流れが上記よりもっと複雑であり、ここで選挙の具体的な細部の部分について紹介している。

**サーバー状態**

　　不同な任務を処理できるため、複数のサーバー状態を設定された。公式パッケージ中に**org.apache.zookeeper.server.quorum.QuorumPeer.ServerState**クラスがその状態を設定されてある。

- **LOOKING**：選挙を進行してる過程でサーバーの状態です。
- **LEADING**：当のサーバーがLeader役を担当する。
- **FOLLOWING**：当のサーバーがFollower役を担当する。
- **OBSERVING**：選挙を参加しないFollowerを理解でき、普通の請求を処理するだけ、特別にObserver役を設定する必要です。

![image-20231101072451012](D:\OneDrive\图片\Typora\image-20231101072451012.png)

**消息隊列**

　　QuorumCnxManagerクラスでは、受信した消息、送信待ちの消息などを保存するために多くの隊列が管理されている。多数の隊列がServerIDに基づいて組み分けされる。

- **recvQueue**： 消息受信の隊列、受信したすべての消息がここに保存される。
- **queueSendMap**： 消息送信の隊列、送信待ちの消息の集合に保存され、Mapとして定義されている。ServerIDに基づいて組み分け、各ServerIDには隊列が関連付けられ、消息の送受信が互いに影響しないようになっている。
- **senderWorkMap**： 送信者の集合。各senderWork送信者は、ZooKeeperとのリモート接続を担当し、消息の送信を担当する。内部ではServerIDに基づいて組み分けされている。
- **lastMessageSent**： 最後に送信された消息。この集合では、毎ServerIDの最新の送信消息が保持される。

![image-20231102112352368](D:\OneDrive\图片\Typora\image-20231102112352368.png)

**キー変数**

　　毎回Leaderを選挙する過程の中に、基本変数の変わりに及んである。選挙段階に需要の変数が**apache.zookeeper.server.quorum.Vote**クラスに定義される。

- **id**：当のサーバーのid番号、も上記のServerIDです。
- **zxid**：トランザクション請求の唯一のID、ID番号が大きいほどデータも最近になる。
- **electionEpoch**：現在で何回投票を記録する。新しい投票に入って１を加えることがある。
- **peerEpoch**：毎回の投票を完了して新たな値を作成してあり、今回の投票を特に表示する。zxidの高さの8位と同じ、低さの8位が今回の投票内に何回トランザクション請求を処理した回数です。

![image-20231102111050057](D:\OneDrive\图片\Typora\image-20231102111050057.png)

**接続の確立**

　　ZooKeeperクラスタ内にペア毎に接続を確立する必要がある。QuorumCnxManagerクラスは、Leader選出の通信ポートを監聴するためにServerSokectを作成し、請求を受信した際にはreceiveConnection関数を呼び出して処理する。ただし、重複したTCP接続の作成を避けるためServerIDが大きいサーバーからServerIDが小さいへの接続を許可する。接続が確立されると、ServerIDに基づいて送信者のsenderWorkerと受信者RecvWorker実体（instance）が作成されます。

**受信と送信**

　　受信者は消息を受信すると、それをrecvQueue隊列に保存する。消息の送信は簡単で、各ServerIDには独立したSendWorkerが存在しているため、queueSendMapから送信するデータを取得し続けるだけです。送信が完了すると、送信したばかりの消息がlastMessageSentに保存される。ただし、注意すべき点は、待ちの送信消息の隊列が空であることがわかった場合、lastMessageSentから直前に送信された消息を取得し、再度消息として送信することです。ZooKeeper自体が重複消息に対して処理機能を持っているため、消息が何か故障で失うより消息を再送信して正しく処理できることが重要です。

**FastLeaderElectionアルゴリズム** 



### 第２節　ZAB協議

　　ZAB（Zookeeper Atomic Broadcast）は崩壊の回復を支持するの原子放送協議です。別の言い方は、ZooKeeperクラスタ内の各サーバー間のデータ整合性を維持するため設計されたの稼働規則という解釈が理解しやすいと思う。ZAB協議が各サーバー間に稼働の流れを説明でき、主にLeader/Follower主従関係の架構を通じてクラスタ全体の整合性を実現してくる。

　　ZAB協議を紹介する前にZookeeperの稼働流れが説明しておく。

![image-20231027144653558](D:\OneDrive\图片\Typora\image-20231027144653558.png)

　　先ず、トランザクション請求（write request）の処理について、Leaderが唯一の担当者となる。どの節点であってもトランザクション請求を受信したら、それをLeader節点に転送して統一に処理する。Leaderが単一の主プロセスで請求の内容に応じてデータを変更操作を順次行う。サーバーのデータの状態が変更されると、対応のバックアップを作成し、その後、バックアップを他の節点に分配し、各サーバーが最新の変更内容を保証できてくる。

　　次に、普通の読み込み請求（read request）について、請求を受信した節点が自身の検査結果を直接返し、Leaderに報告するなど請求が必要ない。

**ZAB協議原理**

　　ZAB協議は、各Leaderが3つの段階（発見、同期、放送）を経る必要があり、その前に必ず全局の唯一のLeaderを選出する。

**選挙（Leader Election）**：各サーバーは自身の投票箱（recvset）を投票する前にその投票箱を空にする。この投票箱には、受け取った投票の記録が含まれる。例えば、Server_2がServer_3に投票し、Server_3がServer_1に投票した場合、Server_1の投票箱は(2,3)、(3,1)、(1,1)となります。（各サーバーはデフォルトで自身に投票します）。

**発見（Discovery）**： ZooKeeperクラスターは必ず1つのLeaderプロセスを選出する必要がある。同時に、LeaderはFollowerの利用可能な節点リストを維持する。この階段、

**同期（Synchronization）**： Leaderは、自身のデータをFollowerと同期させる責任を持ち、複数のバックアップを保存する必要がある。Followerに隊列の未処理の請求を完了した後、受信の情報を本地のログに書き込む。

**放送（Broadcast）**： Leaderは、新しいトランザクション提案があれば、これを全てのFollowerに通知して放送する責任がある。

**ZAB協議核心**

- 全てのトランザクション請求は、全局の唯一のサーバーによって調整されなければならない。このサーバーはLeaderと呼ばれる。残りのサーバーはFollowerサーバー、又はObserverサーバーです。
- Leaderサーバーは、クライアントのトランザクションリク請求をトランザクション提案（Proposal）に変換し、この提案をクラスター内の全てのFollower/Observerサーバーに分配する責任を持つ。つまり、全ての節点にデータの最新の変更内容を送信する。
- 分配後、Leaderサーバーは全てのFollowerからのフィードバック（Ack請求）を待機する。Zab協議では、半数以上のFollowerから正しいAck請求を受信すれば、Leaderは全てのFollowerに対して前回のトランザクション提案をコミットする要求を提出し、再度 Commit メッセージを送信する。

**ZAB協議内容**